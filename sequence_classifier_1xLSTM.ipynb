{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "/Users/stevejpurves/anaconda3/lib/python3.5/importlib/_bootstrap.py:222: RuntimeWarning: compiletime version 3.6 of module 'tensorflow.python.framework.fast_tensor_util' does not match runtime version 3.5\n",
      "  return f(*args, **kwds)\n"
     ]
    }
   ],
   "source": [
    "import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from keras.models import Model\n",
    "from keras.layers import Input, LSTM, Dense\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.utils import to_categorical\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>idWlb</th>\n",
       "      <th>FM</th>\n",
       "      <th>S</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>82.0</td>\n",
       "      <td>82.0</td>\n",
       "      <td>95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>82.0</td>\n",
       "      <td>82.0</td>\n",
       "      <td>95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>82.0</td>\n",
       "      <td>82.0</td>\n",
       "      <td>95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>82.0</td>\n",
       "      <td>82.0</td>\n",
       "      <td>95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>82.0</td>\n",
       "      <td>82.0</td>\n",
       "      <td>95</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   idWlb    FM   S\n",
       "0   82.0  82.0  95\n",
       "1   82.0  82.0  95\n",
       "2   82.0  82.0  95\n",
       "3   82.0  82.0  95\n",
       "4   82.0  82.0  95"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_pickle('training_set.pkl')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[82, 63, 159, 118, 174, 46, 150, 83, 47]\n",
      "10\n",
      "43\n"
     ]
    }
   ],
   "source": [
    "\n",
    "wells = [well for well in df.idWlb.drop_duplicates()]\n",
    "formations = [int(f) for f in df.FM.drop_duplicates()]\n",
    "print(formations)\n",
    "blind_wells = [1486, 107, 1140, 6678, 874, 82, 1411, 3558, 5916, 4244]\n",
    "training_wells = np.setdiff1d(wells, blind_wells)\n",
    "\n",
    "print(len(blind_wells))\n",
    "print(len(training_wells))\n",
    "\n",
    "list_of_wells = [df.loc[df.idWlb == well,['S','FM']] for well in training_wells]\n",
    "list_of_wells[0].head()\n",
    "\n",
    "to_formation_id = np.vectorize(lambda x: formations.index(x))\n",
    "\n",
    "input_sequences = [np.expand_dims(df['S'].values.astype(dtype=np.int), axis=1) for df in list_of_wells]\n",
    "output_sequences = [np.expand_dims(to_formation_id(df['FM'].values.astype(dtype=np.int)), axis=1) for df in list_of_wells]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "43\n"
     ]
    }
   ],
   "source": [
    "batch_size = 1\n",
    "time_step = 5\n",
    "latent_dim=256\n",
    "\n",
    "from keras.preprocessing.sequence import TimeseriesGenerator\n",
    "\n",
    "training_set = []\n",
    "for symbols, targets in zip(input_sequences, output_sequences):\n",
    "    training_set.append(TimeseriesGenerator(symbols, targets,\n",
    "                               length=time_step,\n",
    "                               sampling_rate=1,\n",
    "                               batch_size=batch_size))\n",
    "print(len(training_set))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "input = Input(batch_shape=(batch_size, time_step, 1))\n",
    "lstm = LSTM(latent_dim,\n",
    "            batch_input_shape=(batch_size, time_step, 1))(input)\n",
    "output = Dense(1)(lstm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (1, 5, 1)                 0         \n",
      "_________________________________________________________________\n",
      "lstm_1 (LSTM)                (1, 256)                  264192    \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (1, 1)                    257       \n",
      "=================================================================\n",
      "Total params: 264,449\n",
      "Trainable params: 264,449\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Model(input, output)\n",
    "model.compile(optimizer='rmsprop', loss='mse')\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter 0\n",
      "well 0\n",
      "Epoch 1/1\n",
      "1634/1634 [==============================] - 10s 6ms/step - loss: 0.1940\n",
      "well 1\n",
      "Epoch 1/1\n",
      "   18/10756 [..............................] - ETA: 1:08 - loss: 10.9391"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/stevejpurves/anaconda3/lib/python3.5/site-packages/keras/callbacks.py:435: RuntimeWarning: Can save best model only with acc available, skipping.\n",
      "  'skipping.' % (self.monitor), RuntimeWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10756/10756 [==============================] - 63s 6ms/step - loss: 6.3504\n",
      "well 2\n",
      "Epoch 1/1\n",
      "14467/14467 [==============================] - 88s 6ms/step - loss: 6.3268\n",
      "well 3\n",
      "Epoch 1/1\n",
      "8735/8735 [==============================] - 51s 6ms/step - loss: 0.0181\n",
      "well 4\n",
      "Epoch 1/1\n",
      "6228/6228 [==============================] - 38s 6ms/step - loss: 3.7367\n",
      "well 5\n",
      "Epoch 1/1\n",
      "14545/14545 [==============================] - 88s 6ms/step - loss: 0.1924\n",
      "well 6\n",
      "Epoch 1/1\n",
      "7218/7218 [==============================] - 44s 6ms/step - loss: 1.8048\n",
      "well 7\n",
      "Epoch 1/1\n",
      "13183/13183 [==============================] - 79s 6ms/step - loss: 1.3288\n",
      "well 8\n",
      "Epoch 1/1\n",
      "16069/16069 [==============================] - 95s 6ms/step - loss: 2.2109\n",
      "well 9\n",
      "Epoch 1/1\n",
      "7619/7619 [==============================] - 45s 6ms/step - loss: 1.8884\n",
      "well 10\n",
      "Epoch 1/1\n",
      "9574/9574 [==============================] - 57s 6ms/step - loss: 2.9262\n",
      "well 11\n",
      "Epoch 1/1\n",
      "10901/10901 [==============================] - 65s 6ms/step - loss: 1.7225\n",
      "well 12\n",
      "Epoch 1/1\n",
      "2301/2301 [==============================] - 14s 6ms/step - loss: 0.1386\n",
      "well 13\n",
      "Epoch 1/1\n",
      "5684/5684 [==============================] - 34s 6ms/step - loss: 3.7525\n",
      "well 14\n",
      "Epoch 1/1\n",
      "16162/16162 [==============================] - 96s 6ms/step - loss: 2.5820\n",
      "well 15\n",
      "Epoch 1/1\n",
      "7560/7560 [==============================] - 45s 6ms/step - loss: 2.6295\n",
      "well 16\n",
      "Epoch 1/1\n",
      "7154/7154 [==============================] - 43s 6ms/step - loss: 5.5447\n",
      "well 17\n",
      "Epoch 1/1\n",
      "2968/2968 [==============================] - 18s 6ms/step - loss: 1.9719\n",
      "well 18\n",
      "Epoch 1/1\n",
      "9293/9293 [==============================] - 55s 6ms/step - loss: 1.6307\n",
      "well 19\n",
      "Epoch 1/1\n",
      "2750/2750 [==============================] - 16s 6ms/step - loss: 4.1712\n",
      "well 20\n",
      "Epoch 1/1\n",
      "42/42 [==============================] - 0s 6ms/step - loss: 0.1668\n",
      "well 21\n",
      "Epoch 1/1\n",
      "2864/2864 [==============================] - 17s 6ms/step - loss: 3.7439\n",
      "well 22\n",
      "Epoch 1/1\n",
      "6900/6900 [==============================] - 41s 6ms/step - loss: 2.8622\n",
      "well 23\n",
      "Epoch 1/1\n",
      "6314/6314 [==============================] - 38s 6ms/step - loss: 1.0258\n",
      "well 24\n",
      "Epoch 1/1\n",
      "6658/6658 [==============================] - 40s 6ms/step - loss: 4.1455\n",
      "well 25\n",
      "Epoch 1/1\n",
      "7139/7139 [==============================] - 43s 6ms/step - loss: 3.8172\n",
      "well 26\n",
      "Epoch 1/1\n",
      "4934/4934 [==============================] - 30s 6ms/step - loss: 3.4728\n",
      "well 27\n",
      "Epoch 1/1\n",
      "9242/9242 [==============================] - 55s 6ms/step - loss: 0.3020\n",
      "well 28\n",
      "Epoch 1/1\n",
      "5062/5062 [==============================] - 30s 6ms/step - loss: 0.5761\n",
      "well 29\n",
      "Epoch 1/1\n",
      "10479/10479 [==============================] - 63s 6ms/step - loss: 3.1012\n",
      "well 30\n",
      "Epoch 1/1\n",
      "5483/5483 [==============================] - 33s 6ms/step - loss: 4.5460\n",
      "well 31\n",
      "Epoch 1/1\n",
      "9346/9346 [==============================] - 56s 6ms/step - loss: 2.1748\n",
      "well 32\n",
      "Epoch 1/1\n",
      "5499/5499 [==============================] - 33s 6ms/step - loss: 3.8424\n",
      "well 33\n",
      "Epoch 1/1\n",
      "12128/12128 [==============================] - 73s 6ms/step - loss: 0.2682\n",
      "well 34\n",
      "Epoch 1/1\n",
      "11537/11537 [==============================] - 65s 6ms/step - loss: 4.9062\n",
      "well 35\n",
      "Epoch 1/1\n",
      "6270/6270 [==============================] - 35s 6ms/step - loss: 1.6938\n",
      "well 36\n",
      "Epoch 1/1\n",
      "4956/4956 [==============================] - 28s 6ms/step - loss: 0.1878\n",
      "well 37\n",
      "Epoch 1/1\n",
      "4338/4338 [==============================] - 24s 6ms/step - loss: 3.8966\n",
      "well 38\n",
      "Epoch 1/1\n",
      "5485/5485 [==============================] - 32s 6ms/step - loss: 2.9133\n",
      "well 39\n",
      "Epoch 1/1\n",
      "5887/5887 [==============================] - 38s 7ms/step - loss: 2.0756\n",
      "well 40\n",
      "Epoch 1/1\n",
      "5777/5777 [==============================] - 35s 6ms/step - loss: 1.0300\n",
      "well 41\n",
      "Epoch 1/1\n",
      "6981/6981 [==============================] - 38s 5ms/step - loss: 2.0736\n",
      "well 42\n",
      "Epoch 1/1\n",
      "10766/10766 [==============================] - 65s 6ms/step - loss: 0.3058\n"
     ]
    }
   ],
   "source": [
    "checkpoint = ModelCheckpoint('./1xLSTM_intervals.acc.hdf5', monitor='acc', verbose=1, save_best_only=True, mode='max')\n",
    "\n",
    "num_iter = 1\n",
    "history = []\n",
    "\n",
    "for i in range(0, num_iter):\n",
    "    print(\"iter\", i)\n",
    "    for w, well in enumerate(training_set):\n",
    "        print(\"well\", w)\n",
    "        history.append(model.fit_generator(well,\n",
    "                      epochs=1,\n",
    "                      callbacks=[checkpoint]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# model.save('lstm_1iter_step5.hdf5')\n",
    "model = keras.models.load_model('lstm_1iter_step5.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "list_of_blind_wells = [df.loc[df.idWlb == well,['S','FM']] for well in blind_wells]\n",
    "list_of_blind_wells[0].head()\n",
    "\n",
    "\n",
    "predict_input = [np.expand_dims(df['S'].values.astype(dtype=np.int), axis=1) for df in list_of_blind_wells]\n",
    "predict_target = [np.expand_dims(to_formation_id(df['FM'].values.astype(dtype=np.int)), axis=1) for df in list_of_blind_wells]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from keras.preprocessing.sequence import TimeseriesGenerator\n",
    "inference_set = []\n",
    "for symbols, targets in zip(predict_input, predict_target):\n",
    "    inference_set.append(TimeseriesGenerator(symbols, targets,\n",
    "                               length=time_step,\n",
    "                               sampling_rate=1,\n",
    "                               batch_size=batch_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 6995\n",
      "1 15572\n",
      "2 5380\n",
      "3 7050\n",
      "4 10643\n",
      "5 3483\n",
      "6 11273\n",
      "7 4265\n",
      "8 13279\n",
      "9 2934\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "results = []\n",
    "for w, well_data in enumerate(inference_set):\n",
    "    print(w, len(well_data))\n",
    "    result = []\n",
    "    for n in range(0, len(well_data)):\n",
    "        symbols, _ = well_data[n]\n",
    "        r = model.predict(symbols)[0][0]\n",
    "        f = formations[math.floor(r+0.5)]\n",
    "        result.append(f)   \n",
    "    results.append(result)\n",
    "    \n",
    "# print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1486, 107, 1140, 6678, 874, 82, 1411, 3558, 5916, 4244]\n"
     ]
    }
   ],
   "source": [
    "print(blind_wells)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import gzip\n",
    "import cloudpickle as pickle\n",
    "with gzip.GzipFile('lstm_step5.gzip', 'w') as fs:\n",
    "        pickle.dump(results,fs)\n",
    "        pickle.dump(blind_wells,fs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
